{
    "retrieval_report": [
        "Query: What are the latest advancements in AI research?\n",
        "top-1 chunk: systematic reasoning process that experts use. New researchers can now tackle sophis- ticated analyses without deep specialization in each tool. During critical incidents, teams can rapidly compose diag- nostic solutions spanning multiple measurement domains. Meanwhile, experienced researchers gain a force multiplier, focusing on novel insights while ArachNet handles integra- tion complexity. We open source ArachNet\u2019s prompts and the case studies 1. 2 Related Work There has been research using agentic AI with LLM in net- working problems such as design, configuration, and diag- nosis. ChatNet [16] handles networking tasks from natu- ral language queries but still depends on human interven- tion. NADA [15] uses LLMs to generate network algorithms, 1Prompts and case studies available at https://gitlab.com/netsail- uci/arachnet though generated designs require quality checks. Zhou et al. [28] propose an LLM-based agent that retrieves knowl- edge from Web resources and iteratively self-learns, but gen- erating high-quality research questions still requires human evaluation expertise. Kotaru [18] applies LLMs to help oper- ators translate natural language queries into metric-driven code, yet integration remains challenging due to inconsistent data formats. Unlike these approaches, ArachNet enables end-to-end automated workflow composition across differ- ent measurement tools through a multi-agent architecture that systematically captures expert reasoning patterns from problem decomposition to executable implementation. 3 Design ArachNet treats Internet measurement as a compositional problem where complex analyses emerge from intelligently combining expert-built building blocks. Unlike existing man- ual frameworks requiring users to know which tools ex- ist and how to wire them together, ArachNet captures the problem-solving process itself\u2014the systematic approach ex- perts use to navigate from query to solution. ArachNet uses four specialized agents with carefully designed prompts that mirror how experts work (Figure 1) with each agent han- dling a distinct reasoning phase. By default, the system runs in \"standard\" mode for fully automated workflows. In \"ex- pert\" mode, domain specialists can review and adjust outputs between agents before proceeding to the next stage. Registry: Measurement Capability Encoding. The Reg- istry forms ArachNet\u2019s foundation\u2014a manually curated cat- alog describing what measurement tools can do, not how they do it. This design emerged from early experiments: ex- posing entire codebases to agents overwhelmed them with implementation details, causing them to miss key capabilities buried in thousands of lines of code. ArachNet\u2019s compact registry instead provides agents with a \"measurement API\" for intelligent composition. Each entry specifies a tool\u2019s ca- pabilities (e.g., \"maps IP links to submarine cables\"), required inputs, expected outputs, and constraints. This scales lin- early with available tools, transforming diverse measurement frameworks into unified knowledge that supports automated reasoning. QueryMind: Problem Analysis & Decomposition. Query- Mind transforms user queries into structured sub-problems with clear dependencies and constraints. This separation exists because problem understanding requires different rea- soning than solution design\u2014experts first clarify what needs to be measured before considering how to measure it. The agent recognizes that seemingly simple queries contain hid- den complexity that experts instinctively identify. A request like \"measure CDN performance\" actually includes latency Towards an Agentic Workflow for Internet Measurement Research\n\n",
        "top-2 chunk: models for both (left) base models (Table 4) and (right) instruction-tuned models (Table 6). 1 Introduction The rapid advancement of artificial intelligence, driven in large part by large language models (LLMs) (Gemini Team, 2024; OpenAI, 2023; Dubey et al., 2024; Yang et al., 2025a), has accelerated progress toward artificial general intelligence and transformed society at large. However, much of this progress has been led by proprietary releases (e.g., GPT-4 (OpenAI, 2023), Claude (Anthropic, 2025), Gemini (Gemini Team, 2024)), where training data, methods, and evaluation details remain opaque. While these mod- els have set new state-of-the-art performance, their closed nature hinders scientific understanding, repro- ducibility, and equitable access. 1 arXiv:2511.10628v1 [cs.CL] 13 Nov 2025 In response, the research community has placed increasing emphasis on open-weight models, where trained parameters are released. Projects such as LLaMA-3.2-3B (Dubey et al., 2024), Qwen-2.5-3B (Yang et al., 2024), and Gemma-2-2B (Team et al., 2024) have demonstrated competitive capabilities in relatively compact architectures. Yet most of these remain open-weight rather than fully open: their training data, preprocessing, and training recipes are either undisclosed or proprietary. As a result, researchers cannot fully reproduce the results, audit potential data contamination, or study the effects of data and training choices at scale. To bridge this gap, we introduce Instella, a new family of fully open 3B-parameter language models. In- stella makes available not only model weights, but also the complete training pipeline, datasets, and opti- mization details, thereby offering full transparency. Instead of solely relying on general-purpose corpora, Instella is pretrained in two distinct stages: an initial 4T-token general-domain pre-training stage, followed by a 57B-token second-stage emphasizing reasoning-heavy domains. To further enrich this stage, we in- troduce an in-house synthetic dataset for mathematics, constructed by abstracting GSM8K problems into symbolic Python programs and parameterizing them to generate diverse yet solvable variants. This ap- proach expands mathematical coverage while maintaining the correctness of synthesized data, providing a principled way to inject reasoning signals into pre-training. In addition, we leverage weight ensembling across stochastic pre-training seeds by conducting multiple second-stage runs with different random seeds and merging their weights into the final checkpoint, which further enhances model performance. Following pre-training, Instella undergoes supervised fine-tuning (SFT) on a carefully curated mixture of 2.3 million high-quality instruction-response pairs drawn from diverse domains such as mathematics, coding, com- monsense reasoning, and multi-turn dialogue. This step equips the model with the ability to follow user prompts, handle complex instructions, and generalize across a wide range of task formats, and is further refined through direct preference optimization (DPO) (Rafailov et al., 2023), aligning outputs with human expectations for helpfulness, safety, and factuality. Building on this foundation, we extend Instella into the long-context regime with Instella-Long, capable of processing sequences up to 128K tokens. Instella-Long is trained in two stages of continued pre-training on 40B tokens, followed by long-context SFT and short-context DPO. Because of the limited availability of long- context SFT data, we synthesize long-context instruction-following examples directly from pre-training documents. Compared with other open-weight models,\n\n",
        "top-3 chunk: Schrit- twieser, J.; Anthony, T.; Hughes, E.; Danihelka, I.; and Ryan-Davis, J. 2019. OpenSpiel: A Framework for Rein- forcement Learning in Games. ArXiv:1908.09453. Love, N.; Hinrichs, T.; Haley, D.; Schkufza, E.; and Gene- sereth, M. 2006. General Game Playing: Game Description Language Specification. Technical report, Stanford Logic Group. Pell, B. 1992. METAGAME in Symmetric Chess-Like Games. In Heuristic Programming in Artificial Intelligence: The Third Computer Olympiad. Perez, D.; Samothrakis, S.; Togelius, J.; Schaul, T.; and Lu- cas, S. M. 2016. General Video Game AI: Competition, Challenges and Opportunities. In AAAI Conference on Arti- ficial Intelligence, 4335\u20134337. Piette, \u00b4E.; Soemers, D. J. N. J.; Stephenson, M.; Sironi, C. F.; Winands, M. H. M.; and Browne, C. 2020. Ludii \u2013 The Ludemic General Game System. In Proceedings of the 24th European Conference on Artificial Intelligence, volume 325 of Frontiers in Artificial Intelligence and Applications, 411\u2013 418. Pitrat, J. 1968. Realization of a general game-playing pro- gram. In IFIP Congress, 1570\u20131574. Rasmusen, E. 2007. Games and Information: An Introduc- tion to Game Theory. Blackwell, 4th ed. Schkufza, E.; Love, N.; and Genesereth, M. R. 2008. Propo- sitional Automata and Cell Automata: Representational Frameworks for Discrete Dynamic Systems. In 21st Aus- tralasian Joint Conference on Artificial Intelligence, volume 5360 of LNCS, 56\u201366. Schrittwieser, J.; Antonoglou, I.; Hubert, T.; Simonyan, K.; Sifre, L.; Schmitt, S.; Guez, A.; Lockhart, E.; Hassabis, D.; Graepel, T.; et al. 2020. Mastering atari, go, chess and shogi by planning with a learned model. Nature, 588(7839): 604\u2013 609. Silver, D.; Huang, A.; Maddison, C. J.; Guez, A.; Sifre, L.; van den Driessche, G.; Schrittwieser, J.; Antonoglou, I.; Panneershelvam, V.; Lanctot, M.; Dieleman, S.; Grewe, D.; Nham, J.; Kalchbrenner, N.; Sutskever, I.; Lillicrap, T.; Leach, M.; Kavukcuoglu, K.; Graepel, T.; and Hassabis, D. 2016. Mastering the game of Go with deep neural networks and tree search. Nature, 529: 484\u2013503. Silver, D.; Hubert, T.; Schrittwieser, J.; Antonoglou, I.; Lai, M.; Guez, A.; Lanctot, M.; Sifre, L.; Kumaran, D.; Graepel, T.; et al. 2018. A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. Science, 362(6419): 1140\u20131144. Silver, D.; Schrittwieser, J.; Simonyan, K.; Antonoglou, I.; Huang, A.; Guez, A.; Hubert, T.; Baker, L.; Lai, M.; Bolton, A.; et al. 2017. Mastering the game of Go without human knowledge. Nature, 550(7676): 354\u2013359. Sironi, C. F.; and Winands, M. H. M. 2017. Optimizing Propositional Networks. In Computer Games, 133\u2013151. Springer. Soemers, D. J.; Piette, \u00b4E.; Stephenson, M.; and Browne, C. 2024. The Ludii Game Description Language is Universal. In IEEE Conference on Games, 1\u20138. Tavener, S. 2025. Ai Ai. http://mrraow.com/index.php/aiai- home/. Thielscher, M. 2010. A General Game Description Lan- guage for Incomplete Information Games. In AAAI Con- ference on Artificial Intelligence, 994\u2013999. Thompson, K. 1968. Programming Techniques: Regular Ex- pression Search Algorithm. Commun. ACM, 11(6): 419\u2013 422. A Theoretical Expressiveness Theorem 3. Regular Games is universal for the class of all finite turn-based games, including perfect or imperfect information, and with randomess where probabilities are rational numbers. Proof. Following (Rasmusen 2007), we recall\n\n",
        "Query: Summarize the key techniques used in machine learning.\n",
        "top-1 chunk: compute for entropy estimation as a strictly causal model. Furthermore, the entropy estimates these models yield are inaccurate for tokens near the start of sequences: we find that the first 100 or so tokens are poorly estimated using our nctx = 1024 model. We note that neither of these limitations are insurmountable: firstly, because models trained with smaller context windows would be able to provide accurate per-token entropy estimates for tokens near the start of a sequence, and in the second case because we show empirically that second order entropy estimation models are efficiently trainable. Limited in compute, this work does not directly test some hypotheses put forward and resorts in some cases to observing the limiting behaviors of smaller experiments to infer what would happen for larger ones. Whether these approaches scale as effectively as they are predicted to do so for very large compute is an open question, one that we hope will be picked up by the field and brought to a more satisfactory conclusion in the future. 9.2 Generalization and Entropy Methods for increasing the generalization of machine learning model training abound, but most approaches may be thought of as a conversion of unconstrained optimization to a constrained optimization problem. To illustrate: optimization with L2 weight decay constrains the norms of the weight \u2018vectors\u2019, early stopping constrains the norm of the difference in the weight of the final compared to the initial model state (assuming a fixed or decaying update size), and dropout constrains the combinatorial paths by which information can pass through a model. The training of models using entropy estimates is a departure from these methods: training a model to match an entropy estimate is not strictly speaking constrained optimization as there are no priors placed on the model or optimizer, rather instead the objective function itself is re-parametrized 15 according to both the model\u2019s current loss and the entropy estimates. It may be wondered whether having an efficiently trainable entropy estimator would be useful if compute were to become one day so plentiful that a large model could be trained on all text data in the world, regardless of the likelihood of this scenario. We argue that it is: entropy estimation models may be applied to derived text datasets (proofs etc) as well as other data modalities (audio, visual) to gain more accurate entropy estimates even in this scenario, even if models themselves converge on one representation (Huh et al., 2024). 9.3 Entropy as an Optimization Rate Limiter Per-token entropy estimates may also be useful to accelerate the training convergence of causal language models. The idea that noisy input information should be somehow filtered during gradient-based optimization procedures is not new, and in the context of language modeling, data filtering most often occurs at the level of the source document. It is not inaccurate to view the process of training a causal model on entropy-labeled data as a form of data filtering, but in this case the filtering occurs at the level of\n\n",
        "top-2 chunk: the context of language modeling, data filtering most often occurs at the level of the source document. It is not inaccurate to view the process of training a causal model on entropy-labeled data as a form of data filtering, but in this case the filtering occurs at the level of the token rather than the document. Concepts of information filtering have found their way into model architectures and optimizers themselves: attention mechanism ubiquitous in transformers today was originally introduced in order to effectively filter information from many tokens (Bahdanau et al., 2016), and the most commonly used optimizers today (Adam and AdamW) for language modeling were in a large part designed to deal with stochastic input data by using momentum estimates (Kingma and Ba, 2017). Entropy estimation-based training can also be viewed as performing an analogous noise-filtering method that Adam optimizers do at the parameter level (using second adaptive momentum) but at the level of the token. We leave the investigation of entropy and optimization efficiency to future work. References Claude E Shannon. A mathematical theory of communication. The Bell system technical journal, 27(3): 379\u2013423, 1948. Norbert Wiener. Cybernetics or Control and Communication in the Animal and the Machine. MIT press, 2019. Claude E Shannon. Prediction and entropy of printed english. Bell system technical journal, 30(1):50\u201364, 1951. Fabrice Bellard. Lossless data compression with neural networks. URL: https://bellard. org/nncp/nncp. pdf, 2019. Matt Mahoney. Large text compression benchmark, 2025. URL https://www.mattmahoney.net/dc/text. html#1072. Hutter, Bowery, and Mahoney. 500\u2019000\u20ac prize for compressing human knowledge, 2025. URL http: //prize.hutter1.net/. Bryan C. Knoll. Cmix, 2024. URL https://www.byronknoll.com/cmix.html. Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, et al. The pile: An 800gb dataset of diverse text for language modeling. arXiv preprint arXiv:2101.00027, 2020a. Deepseek. Deepseek-v3 technical report. 2025. URL https://arxiv.org/abs/2412.19437. Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy. The pile: An 800gb dataset of diverse text for language modeling, 2020b. URL https://arxiv.org/abs/2101.00027. 16 Gr\u00e9goire Del\u00e9tang, Anian Ruoss, Paul-Ambroise Duquenne, Elliot Catt, Tim Genewein, Christopher Mattern, Jordi Grau-Moya, Li Kevin Wenliang, Matthew Aitchison, Laurent Orseau, Marcus Hutter, and Joel Veness. Language modeling is compression. 2024. URL https://arxiv.org/abs/2309.10668. Haoran Wei, Yaofeng Sun, and Yukun Li. Deepseek-ocr: Contexts optical compression. 2025. URL https://arxiv.org/abs/2510.18234. Yuval Shalev, Amichai Painsky, and Irad Ben-Gal. Neural joint entropy estimation. 2020. URL https: //arxiv.org/abs/2012.11197. Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals, and Laurent Sifre. Training compute-optimal large language models. 2022. URL https://arxiv.org/abs/2203.15556. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. 2023. URL https://arxiv.org/abs/1706.03762. Benjamin L. Badger. Masked mixers for language generation\n\n",
        "top-3 chunk: Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38\u201345, Online, October 2020. Association for Computational Linguistics. URL https://www.aclweb.org/anthology/2020.emnlp-demos.6. Sylvain Gugger, Lysandre Debut, Thomas Wolf, Philipp Schmid, Zachary Mueller, Sourab Mangrulkar, Marc Sun, and Benjamin Bossan. Accelerate: Training and inference at scale made simple, efficient and adaptable. https://github.com/huggingface/accelerate, 2022. Yanli Zhao, Andrew Gu, Rohan Varma, Liang Luo, Chien-Chin Huang, Min Xu, Less Wright, Hamid Shojanazeri, Myle Ott, Sam Shleifer, Alban Desmaison, Can Balioglu, Pritam Damania, Bernard Nguyen, Geeta Chauhan, Yuchen Hao, Ajit Mathews, and Shen Li. Pytorch fsdp: Experiences on scaling fully sharded data parallel. 2023. URL https://arxiv.org/abs/2304.11277. Quentin Lhoest, Albert Villanova del Moral, Yacine Jernite, Abhishek Thakur, Patrick von Platen, Suraj Patil, Julien Chaumond, Mariama Drame, Julien Plu, Lewis Tunstall, Joe Davison, Mario \u0160a\u0161ko, Gunjan Chhablani, Bhavitvya Malik, Simon Brandeis, Teven Le Scao, Victor Sanh, Canwen Xu, Nicolas Patry, Angelina McMillan-Major, Philipp Schmid, Sylvain Gugger, Cl\u00e9ment Delangue, Th\u00e9o Matussi\u00e8re, Lysandre Debut, Stas Bekman, Pierric Cistac, Thibault Goehringer, Victor Mustar, Fran\u00e7ois Lagunas, Alexander Rush, and Thomas Wolf. Datasets: A community library for natural language processing. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 175\u2013184, Online and Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics. URL https://aclanthology.org/2021.emnlp-demo.21. Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, and Yunfeng Liu. Roformer: Enhanced transformer with rotary position embedding. 2023. URL https://arxiv.org/abs/2104.09864. Marco Ancona, Enea Ceolini, Cengiz \u00d6ztireli, and Markus Gross. Towards better understanding of gradient- based attribution methods for deep neural networks. 2018. URL https://arxiv.org/abs/1711.06104. S1 Appendix S1.1 Experimental Details Training details are found in 3, and we provide more here. We construct models using Pytorch (Paszke et al., 2019), train models using (modified) Hugging Face Transformers (Wolf et al., 2020) trainers with accelerate (Gugger et al., 2022) integration. Most models were trained using Distributed Data Parallel with Pytorch-native automated fp16/fp32 mixed-precision (AMP) which stores weights and parameters in 32-bit precision and downcasts during matrix multiplication, although some were trained using bf16/fp32 mixed precision. A very small number of models were trained using FSDP (Zhao et al., 2023), but training throughputs using this approach were not compared to DDP. We use Datasets (Lhoest et al., 2021) to store, 18 load, and augment data, and typically train using pre-tokenized and pre-processed (padded, entropy estimated etc.) datasets for speed. We train using AdamW with a 500-step warmp-up, a maximum learning rate of \u03b7 = 2 \u221710\u22124 for transformers and \u03b7 = 5 \u221710\u22124 for mixers, with linear learning rate decay to 0 over the full training run (200k steps, or rarely 500k steps). For nctx = 512 experiments, the batch size is b = 128 and for nctx = 1024 we use b = 64. Figure S1: Repeated embedding autoencoder training characterization. (a) Transformers and (b) Masked Mixer-based autoencoder training curves\n\n",
        "Query: Explain the concept of reinforcement learning.\n",
        "top-1 chunk: The Twelfth International Conference on Learning Representations, 2024. [ZLX+23] Chunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et al. LIMA: Less is more for alignment. In Proceedings of NeurIPS, 2023. 11 A Experimental Details A.1 Implement GAD with GRPO We implement policy optimization of the student with GRPO [SWZ+24]. We use qG to denote the output distribution of student G. For each input prompt x, we sample a group of N student responses {yi s}N i=1, and obtain their corresponding rewards {ri s}N i=1, where ri s = D(yi s). The advantage of the i-th response can be calculated with: ri s = D(yi s) (4) Ai = ri s \u2212mean({rj s}N j=1) std({rj s}N j=1) . (5) The student is trained with the following objective: max G E(x,yt)\u223cT ,{yis}N i=1\u223cqG(\u00b7|x) \" 1 N N X i=1 Ai # , (6) where we omit the KL regularizer and the clip operator in GRPO for brevity. For the discriminator, we pair each student response yi s in the group with the same teacher response yt to form (yt, yi s) preference pairs. The discriminator parameters are optimized by minimizing the Bradley-Terry loss across the group: min D E(x,yt)\u223cT ,{yis}N i=1\u223cqG(\u00b7|x) \" 1 N N X i=1 \u2212log \u03c3(D(yt) \u2212D(yi s)) # , (7) where D(yt) is the teacher score shared within the group. A.2 Training Details We train all models with 3 epochs. For GAD, the training consists of 1 warmup epoch followed by 2 GAD training epochs. The models are trained with a batch size of 256, totaling approximately 2400 optimization steps. The PPO mini-batch size for each policy update is also 256. In the warmup stage of GAD, we train the discriminator for 10 steps before jointly training the generator and discriminator. We search learning rate in [1e-6, 5e-6] for GAD and SeqKD baseline. For SeqKD, we find 5e-6 leads to better results in all experiments. For GAD with GPT-5-Chat teacher, we use 1e-6 for both warmup and GAD training stage, and for GAD with Qwen2.5 teacher as in Table 5, we use 5e-6 for warmup stage and 1e-6 for GAD training stage. The maximum context length is set to 2048 tokens for instruction prompts and 1536 for model responses. The training temperature is set to 0.8. In the GRPO algorithm formulated as Equation (6), we set group size N = 8 and the KL weight \u03b2 = 0.001. Distilling Qwen2.5-14B-Instruct from GPT-5-Chat takes about 30 hours on 16 H100 GPUs. 12 A.3 Automatic Evaluation Details The sampling temperature is set to 0.8 and model response length is set to 1536 tokens, same as in training. We use the prompt wrapper in Figure 7 to construct prompts. We use the prompt in Figure 8 for GPT-4o feedback following [GDWH24]. Below is an instruction that describes a task. Write a response that appropriately completes the request. ### Instruction: {instruction} ### Response: Figure 7: The prompt wrapper for training\n\n",
        "top-2 chunk: Schrit- twieser, J.; Anthony, T.; Hughes, E.; Danihelka, I.; and Ryan-Davis, J. 2019. OpenSpiel: A Framework for Rein- forcement Learning in Games. ArXiv:1908.09453. Love, N.; Hinrichs, T.; Haley, D.; Schkufza, E.; and Gene- sereth, M. 2006. General Game Playing: Game Description Language Specification. Technical report, Stanford Logic Group. Pell, B. 1992. METAGAME in Symmetric Chess-Like Games. In Heuristic Programming in Artificial Intelligence: The Third Computer Olympiad. Perez, D.; Samothrakis, S.; Togelius, J.; Schaul, T.; and Lu- cas, S. M. 2016. General Video Game AI: Competition, Challenges and Opportunities. In AAAI Conference on Arti- ficial Intelligence, 4335\u20134337. Piette, \u00b4E.; Soemers, D. J. N. J.; Stephenson, M.; Sironi, C. F.; Winands, M. H. M.; and Browne, C. 2020. Ludii \u2013 The Ludemic General Game System. In Proceedings of the 24th European Conference on Artificial Intelligence, volume 325 of Frontiers in Artificial Intelligence and Applications, 411\u2013 418. Pitrat, J. 1968. Realization of a general game-playing pro- gram. In IFIP Congress, 1570\u20131574. Rasmusen, E. 2007. Games and Information: An Introduc- tion to Game Theory. Blackwell, 4th ed. Schkufza, E.; Love, N.; and Genesereth, M. R. 2008. Propo- sitional Automata and Cell Automata: Representational Frameworks for Discrete Dynamic Systems. In 21st Aus- tralasian Joint Conference on Artificial Intelligence, volume 5360 of LNCS, 56\u201366. Schrittwieser, J.; Antonoglou, I.; Hubert, T.; Simonyan, K.; Sifre, L.; Schmitt, S.; Guez, A.; Lockhart, E.; Hassabis, D.; Graepel, T.; et al. 2020. Mastering atari, go, chess and shogi by planning with a learned model. Nature, 588(7839): 604\u2013 609. Silver, D.; Huang, A.; Maddison, C. J.; Guez, A.; Sifre, L.; van den Driessche, G.; Schrittwieser, J.; Antonoglou, I.; Panneershelvam, V.; Lanctot, M.; Dieleman, S.; Grewe, D.; Nham, J.; Kalchbrenner, N.; Sutskever, I.; Lillicrap, T.; Leach, M.; Kavukcuoglu, K.; Graepel, T.; and Hassabis, D. 2016. Mastering the game of Go with deep neural networks and tree search. Nature, 529: 484\u2013503. Silver, D.; Hubert, T.; Schrittwieser, J.; Antonoglou, I.; Lai, M.; Guez, A.; Lanctot, M.; Sifre, L.; Kumaran, D.; Graepel, T.; et al. 2018. A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. Science, 362(6419): 1140\u20131144. Silver, D.; Schrittwieser, J.; Simonyan, K.; Antonoglou, I.; Huang, A.; Guez, A.; Hubert, T.; Baker, L.; Lai, M.; Bolton, A.; et al. 2017. Mastering the game of Go without human knowledge. Nature, 550(7676): 354\u2013359. Sironi, C. F.; and Winands, M. H. M. 2017. Optimizing Propositional Networks. In Computer Games, 133\u2013151. Springer. Soemers, D. J.; Piette, \u00b4E.; Stephenson, M.; and Browne, C. 2024. The Ludii Game Description Language is Universal. In IEEE Conference on Games, 1\u20138. Tavener, S. 2025. Ai Ai. http://mrraow.com/index.php/aiai- home/. Thielscher, M. 2010. A General Game Description Lan- guage for Incomplete Information Games. In AAAI Con- ference on Artificial Intelligence, 994\u2013999. Thompson, K. 1968. Programming Techniques: Regular Ex- pression Search Algorithm. Commun. ACM, 11(6): 419\u2013 422. A Theoretical Expressiveness Theorem 3. Regular Games is universal for the class of all finite turn-based games, including perfect or imperfect information, and with randomess where probabilities are rational numbers. Proof. Following (Rasmusen 2007), we recall\n\n",
        "top-3 chunk: lane change to avoid otherCar that is stationary in front. Lines 10 and 13 define a distribution of initial conditions, ego and otherCar. For instance, in line 13, otherCar is uniformly randomly sampled on the lane of ego, which it intersects with ego\u2019s view cone. Furthermore, ego is assigned a probabilistic behavior called egoBehavior which is defined on lines 1-5 using try/interrupt statement. By default, ego follows the lane it is on, but changes lane if its distance to the other car is within a distance uniformly randomly sampled from a range of 1 to 15 meters. Note that a behavior can be hierarchically defined using a set of primitive behaviors, which in this case include \u201cfollow lane\u201d and \u201clane change.\u201d Semantics of the Query Language. To define what it means for a video to match a query expressed in SCENIC, we need to understand its semantics. A SCENIC program first generates a scene defining the initial configuration of objects (line 10 and 13); the behaviors in the program then define how the objects behave as a function of the state of the world (e.g., their own positions and those of other objects). In particular, we view a behavior as taking as input a sequence of observations of the environment, forming an input trace, and outputting a series of primitive behaviors, the corresponding output trace. Each element of an input trace is an assignment of concrete values to semantic features, such as objects\u2019 positions, orientations, and lanes occupied by objects. For example, given a finite input trace of three timesteps consisting of se- mantic feature values, e.g. positions and orientations of objects, the egoBehavior Fig. 1. A SCENIC program modeling an ego car making a lane change to avoid a car in front. in Figure 1 can generate a set of output traces, e.g. {\u27e8FL,FL,FL\u27e9, \u27e8FL,LC,FL\u27e9} where FL and LC are abbreviations for the primitive behaviors FollowLane and LaneChange respectively. Note that, due to the probabilistic aspect of the SCENIC be- havior, the ego behavior outputs a set of possible primitive behaviors at each timestep. For example, in line 4 of Figure 1, the interrupt condition for triggering a lane change is defined over a uniform random distribution over an interval of 1 to 15 meters, i.e. Range(1,15). When ego and otherCar are between 1 and 15 meters apart, ei- ther FollowLane or LaneChange could occur depending on the random distance threshold chosen. In such a case, both primitive behaviors are feasible. This semantics of a single behavior extends to the semantics of an entire SCENIC program through synchronous composition: the behaviors of all objects in the program run in parallel, with each one choosing a set of primitive behaviors in each time step. In our example, the set of output traces for the entire program corresponding to the 3-step trace above would be:{{ego : \u27e8FL,FL,FL\u27e9, otherCar : \u27e8St,St,St\u27e9}, {ego : \u27e8FL,LC,FL\u27e9}, otherCar : \u27e8St,St,St\u27e9}}, where each element contains the set of primitive behaviors of each object at each time\n\n",
        "Query: What are the challenges in natural language processing?\n",
        "top-1 chunk: Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38\u201345, Online, October 2020. Association for Computational Linguistics. URL https://www.aclweb.org/anthology/2020.emnlp-demos.6. Sylvain Gugger, Lysandre Debut, Thomas Wolf, Philipp Schmid, Zachary Mueller, Sourab Mangrulkar, Marc Sun, and Benjamin Bossan. Accelerate: Training and inference at scale made simple, efficient and adaptable. https://github.com/huggingface/accelerate, 2022. Yanli Zhao, Andrew Gu, Rohan Varma, Liang Luo, Chien-Chin Huang, Min Xu, Less Wright, Hamid Shojanazeri, Myle Ott, Sam Shleifer, Alban Desmaison, Can Balioglu, Pritam Damania, Bernard Nguyen, Geeta Chauhan, Yuchen Hao, Ajit Mathews, and Shen Li. Pytorch fsdp: Experiences on scaling fully sharded data parallel. 2023. URL https://arxiv.org/abs/2304.11277. Quentin Lhoest, Albert Villanova del Moral, Yacine Jernite, Abhishek Thakur, Patrick von Platen, Suraj Patil, Julien Chaumond, Mariama Drame, Julien Plu, Lewis Tunstall, Joe Davison, Mario \u0160a\u0161ko, Gunjan Chhablani, Bhavitvya Malik, Simon Brandeis, Teven Le Scao, Victor Sanh, Canwen Xu, Nicolas Patry, Angelina McMillan-Major, Philipp Schmid, Sylvain Gugger, Cl\u00e9ment Delangue, Th\u00e9o Matussi\u00e8re, Lysandre Debut, Stas Bekman, Pierric Cistac, Thibault Goehringer, Victor Mustar, Fran\u00e7ois Lagunas, Alexander Rush, and Thomas Wolf. Datasets: A community library for natural language processing. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 175\u2013184, Online and Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics. URL https://aclanthology.org/2021.emnlp-demo.21. Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, and Yunfeng Liu. Roformer: Enhanced transformer with rotary position embedding. 2023. URL https://arxiv.org/abs/2104.09864. Marco Ancona, Enea Ceolini, Cengiz \u00d6ztireli, and Markus Gross. Towards better understanding of gradient- based attribution methods for deep neural networks. 2018. URL https://arxiv.org/abs/1711.06104. S1 Appendix S1.1 Experimental Details Training details are found in 3, and we provide more here. We construct models using Pytorch (Paszke et al., 2019), train models using (modified) Hugging Face Transformers (Wolf et al., 2020) trainers with accelerate (Gugger et al., 2022) integration. Most models were trained using Distributed Data Parallel with Pytorch-native automated fp16/fp32 mixed-precision (AMP) which stores weights and parameters in 32-bit precision and downcasts during matrix multiplication, although some were trained using bf16/fp32 mixed precision. A very small number of models were trained using FSDP (Zhao et al., 2023), but training throughputs using this approach were not compared to DDP. We use Datasets (Lhoest et al., 2021) to store, 18 load, and augment data, and typically train using pre-tokenized and pre-processed (padded, entropy estimated etc.) datasets for speed. We train using AdamW with a 500-step warmp-up, a maximum learning rate of \u03b7 = 2 \u221710\u22124 for transformers and \u03b7 = 5 \u221710\u22124 for mixers, with linear learning rate decay to 0 over the full training run (200k steps, or rarely 500k steps). For nctx = 512 experiments, the batch size is b = 128 and for nctx = 1024 we use b = 64. Figure S1: Repeated embedding autoencoder training characterization. (a) Transformers and (b) Masked Mixer-based autoencoder training curves\n\n",
        "top-2 chunk: Dawn Song, and Jacob Stein- hardt. Measuring massive multitask language understanding, 2021a. URL https://arxiv.org/abs/2009. 03300. Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Stein- hardt. Measuring massive multitask language understanding. In ICLR, 2021b. Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the math dataset, 2021c. URL https: //arxiv.org/abs/2103.03874. 15 Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the math dataset. NeurIPS, 2021d. Shengding Hu, Yuge Tu, Xu Han, Chaoqun He, Ganqu Cui, Xiang Long, Zhi Zheng, Yewei Fang, Yuxiang Huang, Weilin Zhao, et al. Minicpm: Unveiling the potential of small language models with scalable training strategies. arXiv preprint arXiv:2404.06395, 2024. Sam Ade Jacobs, Masahiro Tanaka, Chengming Zhang, Minjia Zhang, Shuaiwen Leon Song, Samyam Ra- jbhandari, and Yuxiong He. Deepspeed ulysses: System optimizations for enabling training of extreme long sequence transformer models. arXiv preprint arXiv:2309.14509, 2023. Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke Zettlemoyer. Triviaqa: A large scale distantly super- vised challenge dataset for reading comprehension. arXiv preprint arXiv:1705.03551, 2017. Tom\u00b4a\u02c7s Ko\u02c7cisk`y, Jonathan Schwarz, Phil Blunsom, Chris Dyer, Karl Moritz Hermann, G\u00b4abor Melis, and Edward Grefenstette. The narrativeqa reading comprehension challenge. Transactions of the Association for Computational Linguistics, 6:317\u2013328, 2018. Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et al. Natural questions: a benchmark for question answering research. Transactions of the Association for Computational Linguistics, 7:453\u2013466, 2019. Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gonza- lez, Hao Zhang, and Ion Stoica. Efficient memory management for large language model serving with pagedattention. In Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles, 2023. Nathan Lambert, Jacob Morrison, Valentina Pyatkin, Shengyi Huang, Hamish Ivison, Faeze Brahman, Lester James V Miranda, Alisa Liu, Nouha Dziri, Shane Lyu, et al. T\u00a8ulu 3: Pushing frontiers in open language model post-training. arXiv preprint arXiv:2411.15124, 2024. Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, et al. Solving quantitative reasoning prob- lems with language models. Advances in neural information processing systems, 35:3843\u20133857, 2022. Jeffrey Li, Alex Fang, Georgios Smyrnis, Maor Ivgi, Matt Jordan, Samir Yitzhak Gadre, Hritik Bansal, Etash Kumar Guha, Sedrick Keh, Kushal Arora, Saurabh Garg, Rui Xin, Niklas Muennighoff, Reinhard Heckel, Jean Mercat, Mayee F Chen, Suchin Gururangan, Mitchell Wortsman, Alon Albalak, Yonatan Bitton, Marianna Nezhurina, Amro Kamal Mohamed Abbas, Cheng-Yu Hsieh, Dhruba Ghosh, Joshua P Gardner, Maciej Kilian, Hanlin Zhang, Rulin Shao, Sarah M Pratt, Sunny Sanyal, Gabriel Ilharco, Giannis Daras, Kalyani Marathe, Aaron Gokaslan, Jieyu Zhang, Khyathi Chandu, Thao Nguyen, Igor Vasiljevic, Sham M. Kakade, Shuran Song, Sujay Sanghavi, Fartash Faghri, Sewoong Oh, Luke Zettlemoyer, Kyle Lo, Alaaeldin El-Nouby, Hadi Pouransari, Alexander T Toshev, Stephanie Wang, Dirk Groeneveld, Luca Soldaini, Pang Wei Koh, Jenia Jitsev,\n\n",
        "top-3 chunk: objectives for medical imaging. arXiv preprint arXiv:2310.12345. Wen-wai Yim, Kirk Roberts, Dina Demner-Fushman, and Yifan Luo. 2023. Overview of the MEDIQA 2023 shared task on consumer health question an- swering. In Proceedings of the 22nd Workshop on Biomedical NLP (BioNLP 2023). Association for Computational Linguistics. Wen-wai Yim, Kirk Roberts, Dina Demner-Fushman, and Yifan Luo. 2025. Overview of the MEDIQA-WV 2025 shared task on wound care response generation. In Proceedings of the 24th Workshop on Biomedical NLP (BioNLP 2025). Association for Computational Linguistics. Xinyue Zhang, Shuo Jiang, Tao Yu, and Hua Xu. 2023. Incorporating structured metadata into clinical text generation. Journal of Biomedical Informatics, 140:104339. A Prompts used in Approach A.1 LLM as Judge Prompt SYSTEM: You are a helpful medical assistant. USER: Given a patient QUERY, and a list of REFERENCE RESPONSES, please evaluate a CANDIDATE RESPONSE using a three-step rat- ing described below. Rating: 0 - CANDIDATE RESPONSE is incom- plete and may contain medically incorrect advice. Rating: 0.5 - CANDIDATE RESPONSE is in- complete but has partially correct medical advice. Rating: 1.0 - CANDIDATE RESPONSE is com- plete and has medically correct advice. The REFERENCE RESPONSES represent an- swers given by domain experts and can be used as references for evaluation. QUERY: REFERENCE RESPONSES: CANDIDATE RESPONSE: RATING: A.2 Mined few shot approach prompt System prompt: You are a clinical AI assistant with expertise in wound care and infection preven- tion, responsible for answering patient queries. Prompt template: Given the patient\u2019s query and associated wound images, your task is to: \u2022 Analyze the query and images together \u2022 Identify likely wound condition or stage \u2022 Suggest appropriate wound care steps (clean- ing, dressing, follow-up) \u2022 Warn if urgent medical attention is required \u2022 Keep the tone concise, clinical, and avoid un- necessary details EXAMPLES: [few shot examples] Now, based on the format of the above examples, generate a response for the following query. Strictly follow the example style and do not include any headings in your response. Patient Query: Query Title: [query title] Query Content: [query content] A.3 Metadata study approach prompt System prompt: You are an expert wound care assistant specializing in interpreting wound images and providing concise, medically sound advice. Given a clinical query and one or more wound images, your job is to deliver short, accurate an- swers based on visible findings and basic wound care principles. Use clinical reasoning to interpret visual cues (e.g., redness, scabbing, swelling, su- tures, necrosis, granulation tissue). You are a medi- cal wound-care assistant. Provide clinically accu- rate and safe guidance based on the query, wound images, and metadata. Your responses should be medically helpful, crisp, and no longer than 2-3 sen- tences. Avoid lengthy explanations or disclaimers. If urgent care is required, clearly recommend it. Otherwise, suggest simple, evidence-based wound care actions. Classification system prompt: You are a wound-care classification assistant. Return wound metadata with calibrated confidence scores. For each field: Choose ONLY from allowed val- ues. Provide a numeric confidence score in [0,1] (0=very unsure, 1=highly certain). For\n\n",
        "Query: Describe the applications of computer vision.\n",
        "top-1 chunk: Li, A. Bardes, S. Petryk, O. Ma\u00f1as, Z. Lin, A. Mahmoud, B. Jayaraman, M. Ibrahim, M. Hall, Y. Xiong, J. Lebensold, C. Ross, S. Jayakumar, C. Guo, D. Bouchacourt, H. Al-Tahan, K. Padthe, V. Sharma, H. Xu, X. E. Tan, M. Richards, S. Lavoie, P. Astolfi, R. A. Hemmat, J. Chen, K. Tirumala, R. Assouel, M. Moayeri, A. Talattof, K. Chaudhuri, Z. Liu, X. Chen, Q. Garrido, K. Ullrich, A. Agrawal, K. Saenko, A. Celikyilmaz, and V. Chandra, \u201cAn introduction to vision-language modeling,\u201d 2024. [Online]. Available: https://arxiv.org/abs/2405.17247 22. H. Taheri and Z. C. Xia, \u201cSlam; definition and evolution,\u201d Engineering Appli- cations of Artificial Intelligence, vol. 97, p. 104032, 2021. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0952197620303092 23. S. Mozaffari, O. Y. Al-Jarrah, M. Dianati, P. Jennings, and A. Mouzakitis, \u201cDeep learning- based vehicle behavior prediction for autonomous driving applications: A review,\u201d IEEE Transactions on Intelligent Transportation Systems, vol. 23, no. 1, pp. 33\u201347, 2022. 24. E. A. Lee and S. A. Seshia, Introduction to Embedded Systems: A Cyber-Physical Systems Approach. MIT Press, 2016. [Online]. Available: http://leeseshia.org 25. D. Shanker, \u201cQuerying labeled time series data with scenario programs,\u201d Master\u2019s thesis, EECS Department, University of California, Berkeley, May 2024. [Online]. Available: http://www2.eecs.berkeley.edu/Pubs/TechRpts/2024/EECS-2024-136.html 26. M. Yannakakis, \u201cHierarchical state machines,\u201d in Proceedings of the International Confer- ence IFIP on Theoretical Computer Science, Exploring New Frontiers of Theoretical Infor- matics, ser. TCS \u201900. Berlin, Heidelberg: Springer-Verlag, 2000, p. 315\u2013330. 27. C. Barrett, R. Sebastiani, S. A. Seshia, and C. Tinelli, \u201cSatisfiability modulo theories,\u201d in Handbook of Satisfiability. IOS Press, 2009, ch. 26, pp. 825\u2013885. 28. S. Van Mierlo and H. Vangheluwe, \u201cIntroduction to statecharts modeling, simulation, testing, and deployment,\u201d in 2019 Winter Simulation Conference (WSC), 2019, pp. 1504\u20131518. 29. M. Holzer and M. Kutrib, \u201cNondeterministic finite automata\u2014recent results on the descrip- tional and computational complexity,\u201d in Implementation and Applications of Automata, O. H. Ibarra and B. Ravikumar, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 2008, pp. 1\u201316. 30. H. Barbosa, C. W. Barrett, M. Brain, G. Kremer, H. Lachnitt, M. Mann, A. Mohamed, M. Mohamed, A. Niemetz, A. N\u00f6tzli, A. Ozdemir, M. Preiner, A. Reynolds, Y. Sheng, C. Tinelli, and Y. Zohar, \u201ccvc5: A versatile and industrial-strength SMT solver,\u201d in Tools and Algorithms for the Construction and Analysis of Systems - 28th International Conference, TACAS 2022, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2022, Munich, Germany, April 2-7, 2022, Proceedings, Part I, ser. Lecture Notes in Computer Science, D. Fisman and G. Rosu, Eds., vol. 13243. Springer, 2022, pp. 415\u2013442. [Online]. Available: https://doi.org/10.1007/978-3-030-99524-9_24 31. OpenAI, \u201cGpt-4: Openai\u2019s advanced language model,\u201d https://openai.com/research/gpt-4, 2024, accessed: 2024-12-16. 32. Anthropic, \u201cClaude: An ai assistant by anthropic,\u201d https://www.anthropic.com, 2024, ac- cessed: 2024-12-16. 33. S. Manmadhan and B. Kovoor, \u201cVisual question answering: a state-of-the-art review,\u201d Artifi- cial Intelligence Review, 2020. 34. S. Moon, H. Woo, H. Park, H. Jung, R. Mahjourian, H. gun Chi, H. Lim, S. Kim, and J. Kim, \u201cVisiontrap: Vision-augmented trajectory prediction guided by textual descriptions,\u201d Euro- pean Conference on Computer Vision (ECCV), 2024. 35.\n\n",
        "top-2 chunk: in the distribution of the output traces generated by the program given the input trace. Related Work. In database systems, numerous video retrieval approaches have been proposed such as BlazeIt [14], VisualWorldDB [15], SVQL [16], and ExSam- ple [17]. These are built using an extension of structured query language (SQL) [18], which severely limits the expressiveness of queries specifying, for instance, only the presence of particular classes of objects, e.g. retrieve videos which contain a motor- cycle and a truck. Spatialyze [19] and our prior work [20] provide expressive query formalisms, yet can only specify static conditions involving objects positions and orien- tations with respect to road structure; they cannot specify temporal behaviors of objects. Conversely, while not as optimized for querying videos, the field of video understand- ing in computer vision backed by vision language models (VLMs) [21] can take very expressive queries in natural language. However, natural language can be an ambigu- ous way to model scenarios, and VLMs currently have limited performance and no guarantees on accuracy. By contrast, we use SCENIC [12] as a query formalism to ex- pressively model scenarios with precise semantics, and provide a query algorithm with a correctness guarantee. In summary, in this paper, we contribute: 1. A novel problem formulation of querying a labeled time series dataset against a formal scenario model, which is applicable to sensor data of any type (e.g., RGB, LiDAR, radar, etc.) assuming the data is appropriately labeled (Sec. 3). 2. A sound query algorithm for a fragment of SCENIC which can be used to validate candidate failure scenarios for diverse perception, behavior prediction, and plan- ning tasks (Sec. 4). 3. Experiments showing that the algorithm is more accurate and orders of magni- tude faster than the state-of-the-art VLMs and can scale linearly to video duration (Sec. 5). 2 Background and Overview In this section, we provide context and examples to facilitate understanding the query problem formulation in Section 3. Given a scenario description and labeled time series sensor data, our query problem is to determine whether the data matches the scenario description. For brevity, and since video is the main type of time series data we use in this paper, we refer to time series sensor data as a video from now on. Query Language. We adopt SCENIC [11, 12] as our query language to formally model scenarios of interest. SCENIC is a probabilistic programming language designed to model and generate scenarios in simulation. A SCENIC program defines a set of objects, a distribution over their initial configuration, or scene (i.e., position, orientation, etc.), and their probabilistic behaviors. The SCENIC program in Fig. 1 models a scenario where ego car follows a lane and makes a lane change to avoid otherCar that is stationary in front. Lines 10 and 13 define a distribution of initial conditions, ego and otherCar. For instance, in line 13, otherCar is uniformly randomly sampled on the lane of ego, which it intersects with ego\u2019s view cone. Furthermore, ego is assigned a\n\n",
        "top-3 chunk: Kovoor, \u201cVisual question answering: a state-of-the-art review,\u201d Artifi- cial Intelligence Review, 2020. 34. S. Moon, H. Woo, H. Park, H. Jung, R. Mahjourian, H. gun Chi, H. Lim, S. Kim, and J. Kim, \u201cVisiontrap: Vision-augmented trajectory prediction guided by textual descriptions,\u201d Euro- pean Conference on Computer Vision (ECCV), 2024. 35. A. Dosovitskiy, G. Ros, F. Codevilla, A. Lopez, and V. Koltun, \u201cCARLA: An open urban driving simulator,\u201d in Proceedings of the 1st Annual Conference on Robot Learning, 2017, pp. 1\u201316. A Proof of Theorem 1 According to our problem statement, the label trace l matches the program P if there exists a window of the label trace of length m \u2208N, whose (1) initial input is in the support of the initial distribution of the program, and (2) the window is a member of the set of program traces generated by the inputs of the window. The condition (1) is checked in Algorithm 2 line 3-4 as the result of invoking the function, Query, in line 6 in Algorithm 1. Thus, we move on to prove that algorithm correctly checks condition (2). For condition (2), we assume that our translation from the SCENIC program to the HFSMs is accurate. This means that, given any input trace, the sets of all possible output traces from the program and those produced by the HFSMs are equivalent. Thus, under this assumption, checking condition (2) above is equivalent to checking that the translated HFSMs of the program can generate a length-m subtrace of the label output trace. Recall that the SCENIC fragment we support (as explained in Sec. 1) prevents any variable assignments except for objects. Therefore, it is not allowed in our SCENIC fragment to define and use a variable in any guard conditions such that the evaluation of the guards require access to the history of inputs. In short, the supported SCENIC fragment computes the guards only based on the current inputs. For this reason, we can make the following inductive argument. By induction over the length of the window m, the invariant of the induction step is that the current states of the HFSMs are the reachable states which are consistent with the observed output of the label trace at each timestep. As a base case, at the initial timestep, t0, the current states of the HFSMs are initialized to the initial base states (Alg. 2 line 4). Then, for each HFSM, the ValidStep function traverses from the topmost initial hierarchical states down to the base states. As the function traverses to each current state, it evaluates all guards of the state based on the current input values and then transitions if any guards become true. Given that the guards are independent of the prior inputs, the function\u2019s evaluation of guards based on only the current input is correct. Thus, ValidStep correctly result in first identifying all the reachable base states at t0. Then, the function applies the pruning of base states to ensure that the reachable base states are consistent\n\n"
    ]
}