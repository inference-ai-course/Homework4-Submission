{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Pipeline Demo - arXiv Papers\n",
    "## Week 4: Retrieval-Augmented Generation\n",
    "\n",
    "This notebook demonstrates the complete RAG pipeline:\n",
    "1. Load processed chunks and FAISS index\n",
    "2. Perform semantic search queries\n",
    "3. Analyze retrieval results\n",
    "4. Generate retrieval report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import numpy as np\n",
    "from embedding_indexer import EmbeddingIndexer\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Model loaded. Embedding dimension: 384\n",
      "FAISS index loaded from: faiss_index.bin\n",
      "Index contains 998 vectors\n",
      "Metadata loaded from: index_metadata.pkl\n",
      "Index Statistics:\n",
      "==================================================\n",
      "total_chunks: 998\n",
      "dimension: 384\n",
      "total_papers: 50\n",
      "avg_chunk_tokens: 500.1743486973948\n"
     ]
    }
   ],
   "source": [
    "# Initialize and load the indexer\n",
    "indexer = EmbeddingIndexer(model_name='all-MiniLM-L6-v2')\n",
    "indexer.load_index('faiss_index.bin', 'index_metadata.pkl')\n",
    "\n",
    "# Display stats\n",
    "stats = indexer.get_stats()\n",
    "print(\"Index Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Test Queries\n",
    "\n",
    "We'll test with 5 different queries covering various NLP topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Queries (5):\n",
      "1. What are attention mechanisms in transformer models?\n",
      "2. How does fine-tuning work for large language models?\n",
      "3. What is the role of tokenization in NLP?\n",
      "4. Explain zero-shot and few-shot learning approaches\n",
      "5. What are the challenges in machine translation?\n"
     ]
    }
   ],
   "source": [
    "test_queries = [\n",
    "    \"What are attention mechanisms in transformer models?\",\n",
    "    \"How does fine-tuning work for large language models?\",\n",
    "    \"What is the role of tokenization in NLP?\",\n",
    "    \"Explain zero-shot and few-shot learning approaches\",\n",
    "    \"What are the challenges in machine translation?\"\n",
    "]\n",
    "\n",
    "print(f\"Test Queries ({len(test_queries)}):\")\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"{i}. {query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Perform Searches and Collect Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed 5 searches\n"
     ]
    }
   ],
   "source": [
    "# Search parameters\n",
    "k = 3  # Top-k results\n",
    "\n",
    "# Store all results\n",
    "all_results = []\n",
    "\n",
    "for query in test_queries:\n",
    "    results = indexer.search(query, k=k)\n",
    "    all_results.append({\n",
    "        'query': query,\n",
    "        'results': results\n",
    "    })\n",
    "\n",
    "print(f\"âœ… Completed {len(all_results)} searches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Display Results for Each Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Query 1: What are attention mechanisms in transformer models?\n",
      "================================================================================\n",
      "\n",
      "Rank 1 (Distance: 0.8744)\n",
      "Paper ID: 2511.12832\n",
      "Chunk ID: 2511.12832_chunk_19\n",
      "\n",
      "Text Preview (first 300 chars):\n",
      "to the â€™realismâ€™ diagnostic task. Figure 5: Layer-wise attention head contributions to the â€™counter offerâ€™ diagnostic task. Causal Influence of Attention Heads on Responses Countering an Offer Attribution Map: Layer-wise Head Contributions Attention Head Index (0-31) Transformer Layer (0-31) Transfo...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Rank 2 (Distance: 0.9693)\n",
      "Paper ID: 2511.12874\n",
      "Chunk ID: 2511.12874_chunk_17\n",
      "\n",
      "Text Preview (first 300 chars):\n",
      "processing pre-trained on a large corpus of text. GPT-2 Generative Pre-trained Transformer 2. An autoregressive language model that uses unidirec- tional attention (each token can only attend to previous tokens). It contains 124 million parameters in its base version and was pre-trained on a larger ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Rank 3 (Distance: 1.0440)\n",
      "Paper ID: 2511.12832\n",
      "Chunk ID: 2511.12832_chunk_20\n",
      "\n",
      "Text Preview (first 300 chars):\n",
      "computed Vsteer was ap- plied during inference. Specifically, for any given input prompt, the hidden activations at the target layer were mod- ified by adding a scaled version of the steering vector to the final 15 token positions. These positions were identified as most influential via attribution ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Query 2: How does fine-tuning work for large language models?\n",
      "================================================================================\n",
      "\n",
      "Rank 1 (Distance: 0.6373)\n",
      "Paper ID: 2511.12991\n",
      "Chunk ID: 2511.12991_chunk_0\n",
      "\n",
      "Text Preview (first 300 chars):\n",
      "Fine-Tuned LLMs Know They Donâ€™t Know: A Parameter-Efficient Approach to Recovering Honesty Zeyu Shi1*, Ziming Wang1*, Tianyu Chen1â€ , Shiqi Gao1, Haoyi Zhou2,3â€  , Qingyun Sun1, Jianxin Li1,3 1SKLCCSE, School of Computer Science and Engineering, Beihang University 2School of Software, Beihang Universi...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Rank 2 (Distance: 0.7594)\n",
      "Paper ID: 2511.13368\n",
      "Chunk ID: 2511.13368_chunk_12\n",
      "\n",
      "Text Preview (first 300 chars):\n",
      "Fei Yuan. 2025. Benchmax: A comprehensive multilingual evaluation suite for large language models.Preprint, arXiv:2502.07346. Pratik Joshi, Sebastin Santy, Amar Budhiraja, Kalika Bali, and Monojit Choudhury. 2020. The state and fate of linguistic diversity and inclusion in the NLP world. InProceedin...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Rank 3 (Distance: 0.7788)\n",
      "Paper ID: 2511.13180\n",
      "Chunk ID: 2511.13180_chunk_11\n",
      "\n",
      "Text Preview (first 300 chars):\n",
      "languages according to whether their mutual TE is symmetric or asymmetric and to examine how many such clusters exist. The advanced performance of MarianMT ( ~75 million weights) compared with the NLLB-200 (Facebook) (~615 million weights) and T5-Base (Google) (âˆ¼ 215 million weights) translators (Ta...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Query 3: What is the role of tokenization in NLP?\n",
      "================================================================================\n",
      "\n",
      "Rank 1 (Distance: 1.1189)\n",
      "Paper ID: 2511.13180\n",
      "Chunk ID: 2511.13180_chunk_2\n",
      "\n",
      "Text Preview (first 300 chars):\n",
      "of sentences, each containing one of the selected token s, results in the probabilities to replace this token by other ones, while preserving the translation. These probabilities constitute the entropy of the selected token, and their average across all selected pivot tokens provides an estimate of ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Rank 2 (Distance: 1.1224)\n",
      "Paper ID: 2511.13182\n",
      "Chunk ID: 2511.13182_chunk_1\n",
      "\n",
      "Text Preview (first 300 chars):\n",
      "when applied with various prompt templates, effectively restore diacritics in Romanian texts? â€“ RQ2. How do the performances of these models compare against a neutral baseline, particularly in terms of Restoration Accuracy and Restoration Error Rates? â€“ RQ3. How do the results of LLMs vary in the co...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Rank 3 (Distance: 1.1359)\n",
      "Paper ID: 2511.12573\n",
      "Chunk ID: 2511.12573_chunk_23\n",
      "\n",
      "Text Preview (first 300 chars):\n",
      "generate responses that preserve the core semantic content while varying the length bin. Specifically, we modify verbosity, style, or structure without introducing new substantive information. The following techniques enable controlled expansion or compression while maintaining meaning: â€¢ Filler Sen...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Query 4: Explain zero-shot and few-shot learning approaches\n",
      "================================================================================\n",
      "\n",
      "Rank 1 (Distance: 1.0977)\n",
      "Paper ID: 2511.12630\n",
      "Chunk ID: 2511.12630_chunk_18\n",
      "\n",
      "Text Preview (first 300 chars):\n",
      "Knots, a comprehensive dataset of 12,347 expert- annotated NOTAMs from 194 Flight Information Re- gions, whose non-extractive, inferential annotation scheme provides a robust foundation for models with genuine semantic understanding. Second, we propose a novel multi-agent collaborative framework, MD...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Rank 2 (Distance: 1.1127)\n",
      "Paper ID: 2511.13152\n",
      "Chunk ID: 2511.13152_chunk_3\n",
      "\n",
      "Text Preview (first 300 chars):\n",
      "for short-answer scoring tasks (Chamieh et al., 2024). LLMs have also been applied to spo- ken grammar evaluation by generating test varia- tions robust to ASR noise (Kopparapu et al., 2024). 3 Proposed Method The proposed method estimates grammar compe- tency without labeled training data by adopti...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Rank 3 (Distance: 1.1175)\n",
      "Paper ID: 2511.13118\n",
      "Chunk ID: 2511.13118_chunk_10\n",
      "\n",
      "Text Preview (first 300 chars):\n",
      "schemas as executable classes, AEC en- ables systematic disambiguation, schema enforcement, and error correction. Experiments on five benchmarks and six LLM backbones show that AEC consistently outperforms strong zero-shot baselines, especially on complex schemas. Our results demonstrate that combin...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Query 5: What are the challenges in machine translation?\n",
      "================================================================================\n",
      "\n",
      "Rank 1 (Distance: 0.8410)\n",
      "Paper ID: 2511.13180\n",
      "Chunk ID: 2511.13180_chunk_11\n",
      "\n",
      "Text Preview (first 300 chars):\n",
      "languages according to whether their mutual TE is symmetric or asymmetric and to examine how many such clusters exist. The advanced performance of MarianMT ( ~75 million weights) compared with the NLLB-200 (Facebook) (~615 million weights) and T5-Base (Google) (âˆ¼ 215 million weights) translators (Ta...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Rank 2 (Distance: 0.8656)\n",
      "Paper ID: 2511.13467\n",
      "Chunk ID: 2511.13467_chunk_19\n",
      "\n",
      "Text Preview (first 300 chars):\n",
      "between future automated document-level scoring systems and expert human judgment, â€¢Improved fairness and consistency across evaluation samples of different lengths, â€¢ More intelligent quality evaluation systems producing evaluations closer to human perception, â€¢Stronger foundations for evaluating b...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Rank 3 (Distance: 0.8660)\n",
      "Paper ID: 2511.13467\n",
      "Chunk ID: 2511.13467_chunk_18\n",
      "\n",
      "Text Preview (first 300 chars):\n",
      "types are directly comparable. For example, replicating the Englishâ€“German marketing case from Table 3 in [LGM+24], a 5,000-word translation with 23 minor errors passed the linear model, but was rejected by human reviewers. The logarithmic model set a threshold of 16 errorsâ€”correctly matching the ex...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for idx, item in enumerate(all_results, 1):\n",
    "    query = item['query']\n",
    "    results = item['results']\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"Query {idx}: {query}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for result in results:\n",
    "        print(f\"\\nRank {result['rank']} (Distance: {result['distance']:.4f})\")\n",
    "        print(f\"Paper ID: {result['paper_id']}\")\n",
    "        print(f\"Chunk ID: {result['chunk_id']}\")\n",
    "        print(f\"\\nText Preview (first 300 chars):\")\n",
    "        print(result['text'][:300] + \"...\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Retrieval Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieval Quality Metrics:\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>avg_distance</th>\n",
       "      <th>min_distance</th>\n",
       "      <th>max_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are attention mechanisms in transformer m...</td>\n",
       "      <td>0.962566</td>\n",
       "      <td>0.874360</td>\n",
       "      <td>1.044035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does fine-tuning work for large language m...</td>\n",
       "      <td>0.725145</td>\n",
       "      <td>0.637259</td>\n",
       "      <td>0.778800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the role of tokenization in NLP?</td>\n",
       "      <td>1.125757</td>\n",
       "      <td>1.118935</td>\n",
       "      <td>1.135897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explain zero-shot and few-shot learning approa...</td>\n",
       "      <td>1.109308</td>\n",
       "      <td>1.097714</td>\n",
       "      <td>1.117514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the challenges in machine translation?</td>\n",
       "      <td>0.857553</td>\n",
       "      <td>0.841021</td>\n",
       "      <td>0.866049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  avg_distance  \\\n",
       "0  What are attention mechanisms in transformer m...      0.962566   \n",
       "1  How does fine-tuning work for large language m...      0.725145   \n",
       "2           What is the role of tokenization in NLP?      1.125757   \n",
       "3  Explain zero-shot and few-shot learning approa...      1.109308   \n",
       "4    What are the challenges in machine translation?      0.857553   \n",
       "\n",
       "   min_distance  max_distance  \n",
       "0      0.874360      1.044035  \n",
       "1      0.637259      0.778800  \n",
       "2      1.118935      1.135897  \n",
       "3      1.097714      1.117514  \n",
       "4      0.841021      0.866049  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Average Distance: 0.9561\n"
     ]
    }
   ],
   "source": [
    "# Calculate average distances\n",
    "distances_by_query = []\n",
    "\n",
    "for item in all_results:\n",
    "    distances = [r['distance'] for r in item['results']]\n",
    "    avg_distance = np.mean(distances)\n",
    "    distances_by_query.append({\n",
    "        'query': item['query'][:50] + '...' if len(item['query']) > 50 else item['query'],\n",
    "        'avg_distance': avg_distance,\n",
    "        'min_distance': min(distances),\n",
    "        'max_distance': max(distances)\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df_distances = pd.DataFrame(distances_by_query)\n",
    "print(\"\\nRetrieval Quality Metrics:\")\n",
    "print(\"=\" * 80)\n",
    "display(df_distances)\n",
    "\n",
    "print(f\"\\nOverall Average Distance: {df_distances['avg_distance'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Paper Coverage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Frequently Retrieved Papers:\n",
      "==================================================\n",
      "2511.13180: 3 times\n",
      "2511.12832: 2 times\n",
      "2511.13467: 2 times\n",
      "2511.12874: 1 times\n",
      "2511.12991: 1 times\n",
      "2511.13368: 1 times\n",
      "2511.13182: 1 times\n",
      "2511.12573: 1 times\n",
      "2511.12630: 1 times\n",
      "2511.13152: 1 times\n",
      "\n",
      "Total unique papers in results: 11\n"
     ]
    }
   ],
   "source": [
    "# Analyze which papers appear in results\n",
    "paper_frequency = {}\n",
    "\n",
    "for item in all_results:\n",
    "    for result in item['results']:\n",
    "        paper_id = result['paper_id']\n",
    "        paper_frequency[paper_id] = paper_frequency.get(paper_id, 0) + 1\n",
    "\n",
    "# Sort by frequency\n",
    "sorted_papers = sorted(paper_frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Most Frequently Retrieved Papers:\")\n",
    "print(\"=\" * 50)\n",
    "for paper_id, count in sorted_papers[:10]:\n",
    "    print(f\"{paper_id}: {count} times\")\n",
    "\n",
    "print(f\"\\nTotal unique papers in results: {len(paper_frequency)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Retrieval Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Retrieval report saved to: retrieval_report.json\n"
     ]
    }
   ],
   "source": [
    "# Create a comprehensive report\n",
    "report = {\n",
    "    'metadata': {\n",
    "        'total_queries': len(all_results),\n",
    "        'results_per_query': k,\n",
    "        'index_stats': stats\n",
    "    },\n",
    "    'queries_and_results': []\n",
    "}\n",
    "\n",
    "for item in all_results:\n",
    "    query_report = {\n",
    "        'query': item['query'],\n",
    "        'results': [\n",
    "            {\n",
    "                'rank': r['rank'],\n",
    "                'distance': r['distance'],\n",
    "                'paper_id': r['paper_id'],\n",
    "                'chunk_id': r['chunk_id'],\n",
    "                'text': r['text']\n",
    "            }\n",
    "            for r in item['results']\n",
    "        ]\n",
    "    }\n",
    "    report['queries_and_results'].append(query_report)\n",
    "\n",
    "# Save report\n",
    "with open('retrieval_report.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(report, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"âœ… Retrieval report saved to: retrieval_report.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interactive Query Test\n",
    "\n",
    "Try your own custom queries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Query: What does the paper Attention is all you need talk about?\n",
      "================================================================================\n",
      "\n",
      "ðŸ“„ Rank 1 | Distance: 1.1351\n",
      "Paper: 2511.13505\n",
      "\n",
      "and a diversity of perspectives in such cases should be actively sought rather than normalized through strict majority-capping. Figure 8: Performance of each model using the CoT + Prompt Chaining prompt averaged across 3 runs. F Prompting Experiment Prompts F.1 CoT F.1.1 CoT System Prompt Your task is to annotate a public narrative speech according to a specific codebook developed by Dr. Marshall ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ“„ Rank 2 | Distance: 1.1397\n",
      "Paper: 2511.13505\n",
      "\n",
      "Applying Large Language Models to Characterize Public Narratives Elinor Poole-Dayan* MIT elinorpd@mit.edu Daniel T. Kesslerâˆ— MIT kessler1@mit.edu Hannah Chiou Wellesley College Margaret Hughes MIT Emily S. Lin Harvard University Marshall Ganz Harvard University Deb Roy MIT Abstract Public Narratives (PNs) are key tools for lead- ership development and civic mobilization, yet their systematic analy...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ“„ Rank 3 | Distance: 1.1577\n",
      "Paper: 2511.13505\n",
      "\n",
      "MaÃ«l Kubli. 2023. Chatgpt outperforms crowd workers for text-annotation tasks.Proceedings of the National Academy of Sciences, 120(30):e2305016120. Anne Hamby and David Brinberg. 2016. Happily Ever After: How Ending Valence Influences Narrative Per- suasion in Cautionary Stories.Journal of Advertising, 45(4):498â€“508. Greg Hampton. 2004. Enhancing public participation through narrative analysis.ERA...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Interactive search function\n",
    "def interactive_search(query, k=3):\n",
    "    \"\"\"Search and display results nicely\"\"\"\n",
    "    results = indexer.search(query, k=k)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for result in results:\n",
    "        print(f\"\\nðŸ“„ Rank {result['rank']} | Distance: {result['distance']:.4f}\")\n",
    "        print(f\"Paper: {result['paper_id']}\")\n",
    "        print(f\"\\n{result['text'][:400]}...\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "interactive_search(\"What does the paper Attention is all you need talk about?\", k=3)\n",
    "# Example: Try your own query\n",
    "# interactive_search(\"What is BERT and how does it work?\", k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "- Loading and using the FAISS index\n",
    "- Performing semantic search on arXiv papers\n",
    "- Analyzing retrieval quality\n",
    "- Generating a comprehensive report\n",
    "\n",
    "**Next Steps:**\n",
    "1. Test the FastAPI service (`python main.py`)\n",
    "2. Explore different chunking strategies\n",
    "3. Experiment with different embedding models\n",
    "4. Add hybrid search (BM25 + dense embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (class4-venv)",
   "language": "python",
   "name": "class4-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
